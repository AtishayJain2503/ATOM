{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d74a86c3-3bad-4fa5-bc58-1631ea904ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb519ce-a84d-4e3f-a53e-7a9e7ba61b39",
   "metadata": {},
   "source": [
    "#### IMPORTING NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f8379cc-1f66-4426-8b59-86a4e7c5bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance==0.2.43 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.2.43)\n",
      "Requirement already satisfied: gradio==4.42.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.42.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: plotly==5.24.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (5.24.0)\n",
      "Requirement already satisfied: tabulate==0.9.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: prettytable==3.11.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.11.0)\n",
      "Requirement already satisfied: tslearn==0.6.3 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: hmmlearn==0.3.2 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: pandas-ta==0.3.14b0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.3.14b0)\n",
      "Requirement already satisfied: ta==0.11.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: pandas==2.0.3 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy==1.24.4 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: matplotlib==3.7.5 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (4.2.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (2.4.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (2.32.3)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (2024.1)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (5.3.0)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (3.17.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (1.1)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from yfinance==0.2.43) (0.0.11)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.27.2)\n",
      "Requirement already satisfied: fastapi in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.112.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (6.4.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (3.10.7)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (2.2.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0; sys_platform != \"emscripten\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.30.6)\n",
      "Requirement already satisfied: ruff>=0.2.2; sys_platform != \"emscripten\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.6.3)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.12.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (23.2.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.0.9)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (2.10.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (2.1.5)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (4.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.24.6)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (4.12.2)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.4.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (10.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (24.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.25.1)\n",
      "Requirement already satisfied: typer<1.0,>=0.12; sys_platform != \"emscripten\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (0.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio==4.42.0) (6.0.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio-client==1.3.0) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gradio-client==1.3.0) (12.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from plotly==5.24.0) (9.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from prettytable==3.11.0) (0.2.13)\n",
      "Requirement already satisfied: scipy in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tslearn==0.6.3) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tslearn==0.6.3) (1.3.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tslearn==0.6.3) (1.4.2)\n",
      "Requirement already satisfied: numba in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tslearn==0.6.3) (0.58.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas==2.0.3) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas==2.0.3) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib==3.7.5) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib==3.7.5) (4.53.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib==3.7.5) (3.1.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib==3.7.5) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib==3.7.5) (1.1.1)\n",
      "Requirement already satisfied: traitlets in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib-inline==0.1.7) (5.14.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.31->yfinance==0.2.43) (3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.31->yfinance==0.2.43) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.31->yfinance==0.2.43) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.43) (2.6)\n",
      "Requirement already satisfied: webencodings in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from html5lib>=1.1->yfinance==0.2.43) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from html5lib>=1.1->yfinance==0.2.43) (1.16.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from httpx>=0.24.1->gradio==4.42.0) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from httpx>=0.24.1->gradio==4.42.0) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from fastapi->gradio==4.42.0) (0.38.4)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio==4.42.0) (3.20.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from uvicorn>=0.14.0; sys_platform != \"emscripten\"->gradio==4.42.0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from uvicorn>=0.14.0; sys_platform != \"emscripten\"->gradio==4.42.0) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.42.0) (1.2.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.42.0) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.42.0) (3.15.4)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pydantic>=2.0->gradio==4.42.0) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pydantic>=2.0->gradio==4.42.0) (0.7.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from typer<1.0,>=0.12; sys_platform != \"emscripten\"->gradio==4.42.0) (13.8.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from typer<1.0,>=0.12; sys_platform != \"emscripten\"->gradio==4.42.0) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->tslearn==0.6.3) (3.5.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from numba->tslearn==0.6.3) (8.4.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from numba->tslearn==0.6.3) (0.41.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0; sys_platform != \"emscripten\"->gradio==4.42.0) (0.4.6)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12; sys_platform != \"emscripten\"->gradio==4.42.0) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12; sys_platform != \"emscripten\"->gradio==4.42.0) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12; sys_platform != \"emscripten\"->gradio==4.42.0) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\nischay\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance==0.2.43 gradio==4.42.0 gradio-client==1.3.0 plotly==5.24.0 tabulate==0.9.0 prettytable==3.11.0 tslearn==0.6.3 hmmlearn==0.3.2 pandas-ta==0.3.14b0 ta==0.11.0 pandas==2.0.3 numpy==1.24.4 matplotlib==3.7.5 matplotlib-inline==0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b80aed-e37b-4b33-8fc9-72777c6f3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as  plt\n",
    "import gradio as gr\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import datetime\n",
    "import time\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from hmmlearn import hmm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tabulate import tabulate\n",
    "from prettytable import PrettyTable\n",
    "import math\n",
    "import seaborn as sns\n",
    "from tslearn.metrics import dtw\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54498604-3570-4c09-b4e0-002a213cebd5",
   "metadata": {},
   "source": [
    " ### BACKTESTING ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0009f64d-b305-47a2-ae78-e0813eec880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskManagement:\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    '''This function is to set the stop-loss depending on entry price'''\n",
    "    @staticmethod\n",
    "    def set_stop_loss(ts, i):\n",
    "        ts.sample = 1\n",
    "        if ts.current_position == 1:\n",
    "            ts.current_stop_loss_value = (1 - ts.stop_loss_percent*ts.sample) * (ts.current_trade_peak)\n",
    "        elif ts.current_position == -1:\n",
    "            ts.current_stop_loss_value = (1 + ts.exit_short_percent*ts.sample) * (ts.current_trade_peak)\n",
    "\n",
    "    '''This function is used to update the stop-loss value, if the portfolio value increases (TRAILING STOP-LOSS)'''\n",
    "    @staticmethod\n",
    "    def update_stop_loss(ts, i):\n",
    "        if ts.current_position == 1:\n",
    "            if ts.holding * ts.close[i] > ts.current_trade_peak:\n",
    "                ts.current_trade_peak = ts.holding * ts.close[i]\n",
    "                RiskManagement.set_stop_loss(ts, i)\n",
    "        elif ts.current_position == -1:\n",
    "            if ts.capital - ts.holding * ts.close[i] < ts.current_trade_peak:\n",
    "                ts.current_trade_peak = ts.capital - ts.holding * ts.close[i]\n",
    "                RiskManagement.set_stop_loss(ts, i)\n",
    "\n",
    "    '''This function is to set the take-profit depending on entry price'''\n",
    "    @staticmethod\n",
    "    def set_take_profit(ts, i):\n",
    "        ts.sample=1\n",
    "        if ts.current_position == 1:\n",
    "            ts.take_profit_value = (1 + ts.take_profit_percent*ts.sample) * (ts.current_portfolio_value)\n",
    "        elif ts.current_position == -1:\n",
    "            ts.take_profit_value = (1 - ts.take_profit_percent*ts.sample) * (ts.current_portfolio_value)\n",
    "\n",
    "class TradingStrategy_Compounding:\n",
    "\n",
    "    '''This function initializes the class according to the data provided, it creates several variables for inside the class, as described'''\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.capital = 100000 # current capital\n",
    "        self.data = data # data (OHLCV and signals)\n",
    "\n",
    "        self.datetime = [] # datetime colmun\n",
    "        self.low = data.low\n",
    "        self.portfolio_value = [] # portfolio value at each index\n",
    "        self.quantity = [] # holding at each index\n",
    "        self.current_position = 0 # current position\n",
    "        self.holding = 0 # current holding\n",
    "        self.sample = 1\n",
    "        self.current_portfolio_value = 0 # current portfolio value\n",
    "        self.mul = 5\n",
    "        self.current_stop_loss_value = 0 # stop-loss value\n",
    "        self.current_trade_peak = 0 # for trailing stop-loss\n",
    "        self.stop_loss_percent = 0.15# stop-loss percent/\n",
    "        self.exit_short_percent = 100# exit condition fo/r short trade\n",
    "        self.take_profit_value = 0 # temporary variable for the trade in action\n",
    "        self.take_profit_percent = 0.35 # take-profit percen/t\n",
    "        self.multipleir = 1\n",
    "        self.stop_loss_count = [] # stop-loss count\n",
    "        self.take_profit_count = [] # take-profit count\n",
    "\n",
    "        self.entry = [] # entry index of\n",
    "        self.exit = [] # exit index\n",
    "        self.new_signals = [] # list of new signals\n",
    "        self.close = data['close'] # close value of btc-usdt\n",
    "\n",
    "        self.trade_type = [] # this is for trade type, according to entry type\n",
    "        self.drawdown = [] # this is drawdown for each day\n",
    "        self.benchmark_return = (((100000/self.close[0]) * self.close[len(self.data) - 1] - 100000)) # this is benchmark returns, according to buy & hold\n",
    "\n",
    "        self.signals = data['signals'] # signals column according to strategy\n",
    "        self.transaction_percentage = 0.00\n",
    "\n",
    "        self.risk_free_rate = 0.05 # you can change it\n",
    "\n",
    "        self.amount_in_trade = []\n",
    "\n",
    "        self.trade_wise_returns = []\n",
    "        self.PL_in_dollars = []\n",
    "\n",
    "        self.amount_invested_in_trade = []\n",
    "\n",
    "        if self.signals.empty:\n",
    "            print(\"No signals generated, empty array encountered.\")\n",
    "\n",
    "    '''This function is used to start a long position on the equity'''\n",
    "    def take_long_position(self,i):\n",
    "        self.current_position = 1\n",
    "        self.holding = self.capital / self.close[i] # as we buy the equity from all the capital we posses\n",
    "        self.capital = 0\n",
    "        self.new_signals.append(1)\n",
    "        self.quantity.append(self.holding)\n",
    "        self.current_portfolio_value = self.holding * self.close[i]\n",
    "        self.portfolio_value.append(self.current_portfolio_value)\n",
    "        self.entry.append(i)\n",
    "        self.trade_type.append('long')\n",
    "        self.amount_in_trade.append(self.current_portfolio_value)\n",
    "        self.amount_invested_in_trade.append(self.current_portfolio_value)\n",
    "\n",
    "    '''This function is used to start a short position on the equity'''\n",
    "    def take_short_position(self,i):\n",
    "        self.current_position = -1\n",
    "        self.holding = self.capital / self.close[i]\n",
    "        self.capital = 2 * self.capital\n",
    "        self.new_signals.append(-1)\n",
    "        self.quantity.append(self.holding)\n",
    "        self.current_portfolio_value = self.capital - self.holding * self.close[i]\n",
    "        self.portfolio_value.append(self.current_portfolio_value)\n",
    "        self.entry.append(i)\n",
    "        self.trade_type.append('short')\n",
    "        self.amount_in_trade.append(self.current_portfolio_value)\n",
    "        self.amount_invested_in_trade.append(self.current_portfolio_value)\n",
    "\n",
    "    '''This function is called when we currently have no position, and do not intend to start either. So portfolio value will be same as capital'''\n",
    "    def update_no_trade(self,i):\n",
    "        self.current_position = 0\n",
    "        self.new_signals.append(0)\n",
    "        self.holding = 0\n",
    "        self.portfolio_value.append(self.capital)\n",
    "        self.quantity.append(0)\n",
    "\n",
    "    '''This function is called when we are currently on long, and we don't want to exit the trade,so current holding and capital remain same'''\n",
    "    def update_long_trade(self, i):\n",
    "        self.current_position = 1\n",
    "        self.quantity.append(self.holding)\n",
    "        self.current_portfolio_value = self.holding * self.close[i]\n",
    "        self.portfolio_value.append(self.current_portfolio_value)\n",
    "        self.new_signals.append(0)\n",
    "\n",
    "    '''This function is called when we are currently on short, and we don't want to exit the trade,so current holding and capital remain same'''\n",
    "    def update_short_trade(self, i):\n",
    "        self.current_position = -1\n",
    "        self.quantity.append(self.holding)\n",
    "        self.current_portfolio_value = self.capital - self.holding * self.close[i]\n",
    "        self.portfolio_value.append(self.current_portfolio_value)\n",
    "        self.new_signals.append(0)\n",
    "\n",
    "    '''This function is called when we want to exit a long trade, so we will increase in hand capital in this case'''\n",
    "    def close_long_trade(self, i):\n",
    "        self.current_position = 0\n",
    "        self.quantity.append(0)\n",
    "        self.capital = self.close[i] * self.holding\n",
    "        self.current_portfolio_value = self.capital\n",
    "        self.portfolio_value.append(self.current_portfolio_value)\n",
    "        self.new_signals.append(-1)\n",
    "        self.exit.append(i)\n",
    "        self.amount_in_trade.append(self.current_portfolio_value)\n",
    "\n",
    "    '''This function is called when we want to exit a short trade, so we will increase in hand capital in this case'''\n",
    "    def close_short_trade(self, i):\n",
    "        self.current_position = 0\n",
    "        self.capital = self.capital - self.close[i] * self.holding\n",
    "        self.quantity.append(0)\n",
    "        self.current_portfolio_value = self.capital\n",
    "        self.portfolio_value.append(self.current_portfolio_value)\n",
    "        self.new_signals.append(1)\n",
    "        self.exit.append(i)\n",
    "        self.amount_in_trade.append(self.current_portfolio_value)\n",
    "\n",
    "    '''This function is called when we are currently on long/short position. It checks if we should exit the trade based on stop-loss and take-profit'''\n",
    "    def check_exit_condition(self, i):\n",
    "        if self.current_position == 1:\n",
    "            temp_value = self.holding * self.close[i]\n",
    "            if temp_value < self.current_stop_loss_value:\n",
    "                self.stop_loss_count.append(i)\n",
    "                return 1\n",
    "\n",
    "            elif temp_value >= self.take_profit_value:\n",
    "                self.take_profit_count.append(i)\n",
    "                return 1\n",
    "\n",
    "        elif self.current_position == -1:\n",
    "            temp_value = self.capital - self.holding * self.close[i]\n",
    "            if temp_value < self.current_stop_loss_value:\n",
    "                self.stop_loss_count.append(i)\n",
    "                return 1\n",
    "            elif temp_value >= self.take_profit_value:\n",
    "                self.take_profit_count.append(i)\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    '''This is the function, which when called will analyse all the trades'''\n",
    "    def compounding(self):\n",
    "\n",
    "        x = len(self.data) - 1 # last trade will be dealt later\n",
    "        for i in range(x):\n",
    "            self.datetime.append(self.data.datetime[i])\n",
    "            if self.capital < 0: # this possibility may arise in compounding approach\n",
    "                print('capital wiped')\n",
    "\n",
    "            if self.current_position == 0:\n",
    "\n",
    "                if self.signals[i] == 0:\n",
    "                    self.update_no_trade(i)\n",
    "                elif self.signals[i] == 1:\n",
    "                    self.take_long_position(i) # to start a new long position\n",
    "                    self.current_trade_peak = self.current_portfolio_value\n",
    "                    RiskManagement.set_take_profit(self, i)\n",
    "                    RiskManagement.set_stop_loss(self, i)\n",
    "                elif self.signals[i] == -1:\n",
    "                    self.take_short_position(i) # to start a new short position\n",
    "                    self.current_trade_peak = self.current_portfolio_value\n",
    "                    RiskManagement.set_take_profit(self, i)\n",
    "                    RiskManagement.set_stop_loss(self, i)\n",
    "\n",
    "            elif self.current_position == 1:\n",
    "                if self.signals[i] == 0 or self.signals[i] == 1:\n",
    "                    if self.check_exit_condition(i) == 1:\n",
    "                        self.close_long_trade(i) # to close a long position\n",
    "                    else:\n",
    "                        RiskManagement.update_stop_loss(self, i)\n",
    "                        self.update_long_trade(i)\n",
    "                else:\n",
    "                    self.close_long_trade(i) # to close a long position\n",
    "\n",
    "            elif self.current_position == -1:\n",
    "                if self.signals[i] == 0 or self.signals[i] == -1:\n",
    "                    if self.check_exit_condition(i) == 1:\n",
    "                        self.close_short_trade(i) # to close a short position\n",
    "                    else:\n",
    "                        RiskManagement.update_stop_loss(self, i)\n",
    "                        self.update_short_trade(i)\n",
    "                else:\n",
    "                    self.close_short_trade(i) # to close a short position\n",
    "\n",
    "        # for the last trade\n",
    "        self.datetime.append(self.data.datetime[x])\n",
    "\n",
    "        if self.current_position == 1:\n",
    "            self.close_long_trade(x)\n",
    "        elif self.current_position == -1:\n",
    "            self.close_short_trade(x)\n",
    "        else:\n",
    "            self.update_no_trade(i)\n",
    "\n",
    "        '''''''''''''''''''''''''''''''''''''''''''''''Trade log completed'''''''''''''''''''''''''''''''''''''''''''''''\n",
    "        # calculating remaining parameters\n",
    "\n",
    "        self.trade_wise_duration = np.array(self.exit) - np.array(self.entry)\n",
    "        self.trade_wise_profit = []\n",
    "        self.trade_wise_loss = []\n",
    "\n",
    "        for i in range(len(self.entry)):\n",
    "            current_trade_return = 100*((self.portfolio_value[self.exit[i]]/self.portfolio_value[self.entry[i]])-1)\n",
    "            self.PL_in_dollars.append(self.portfolio_value[self.exit[i]]-self.portfolio_value[self.entry[i]])\n",
    "            self.trade_wise_returns.append(current_trade_return)\n",
    "            if current_trade_return >= 0:\n",
    "                self.trade_wise_profit.append(current_trade_return)\n",
    "            else:\n",
    "                self.trade_wise_loss.append(current_trade_return)\n",
    "\n",
    "        self.gross_profit = np.sum(self.PL_in_dollars)\n",
    "        self.calculate_transaction_cost()\n",
    "        self.net_profit = self.gross_profit - self.transaction_cost\n",
    "        self.returns = self.net_profit / 100000 * 100\n",
    "\n",
    "        metricstr = Compounding_Results.print_parameters(self)\n",
    "        return Compounding_Results.create_strategy_dataframes(self) , Compounding_Results.create_trade_wise_dataframe(self) , Compounding_Results.create_every_day_dataframe(self), None, \"\".join([str(i[0])+ \" : \" +str(i[1])+\"\\n\" for i in metricstr])\n",
    "\n",
    "    def calculate_transaction_cost(self):\n",
    "        self.transaction_cost = 0\n",
    "        for i in range(len(self.entry)):\n",
    "            self.transaction_cost =0\n",
    "class Compounding_Results:\n",
    "    def _init_(self):\n",
    "        return\n",
    "\n",
    "    '''After backtesting is complete, this function generated a dataframe which is the final one, after take-profit and stop-loss is implemented'''\n",
    "    @staticmethod\n",
    "    def create_strategy_dataframes(ts):\n",
    "        to_submit = pd.DataFrame(columns=['datetime'])\n",
    "        to_submit['datetime'] = ts.datetime\n",
    "        to_submit['open'] = ts.data.open\n",
    "        to_submit['high'] = ts.data.high\n",
    "        to_submit['low'] = ts.data.low\n",
    "        to_submit['close'] = ts.data.close\n",
    "        to_submit['volume'] = ts.data.volume\n",
    "        to_submit['signals'] = ts.new_signals\n",
    "        return to_submit\n",
    "\n",
    "    '''This function generated a trade-log for our strategy, giving returns in each trade'''\n",
    "    @staticmethod\n",
    "    def create_trade_wise_dataframe(ts):\n",
    "        trade_wise = pd.DataFrame(columns=['entry', 'exit'])\n",
    "        trade_wise['entry'] = ts.entry\n",
    "        trade_wise['exit'] = ts.exit\n",
    "        trade_wise['duration'] = ts.trade_wise_duration\n",
    "        trade_wise['trade type'] = ts.trade_type\n",
    "        trade_wise['returns'] = ts.trade_wise_returns\n",
    "        return trade_wise\n",
    "\n",
    "    '''This function creates and everyday log of our strategy, to analyze the portfolio value and drawdown for each day'''\n",
    "    @staticmethod\n",
    "    def create_every_day_dataframe(ts):\n",
    "        every_day = pd.DataFrame(columns=['datetime', 'portfolio value', 'quantity'])\n",
    "        every_day['datetime'] = ts.datetime\n",
    "        every_day['quantity'] = ts.quantity\n",
    "        every_day['portfolio value'] = ts.portfolio_value\n",
    "        every_day['daily_return'] = every_day['portfolio value'].pct_change()\n",
    "        every_day['signals'] = every_day['portfolio value'].pct_change()\n",
    "        every_day['signals'] = ts.new_signals\n",
    "        every_day['Close'] = ts.data.close # not needed\n",
    "        return every_day\n",
    "\n",
    "    '''This function is used to print the necassary parameters, useful for analyzing our strategy'''\n",
    "    @staticmethod\n",
    "    def print_parameters(ts):\n",
    "        # Plotting portfolio value\n",
    "        try:\n",
    "            maxd=0\n",
    "            maxp=0\n",
    "            for i in ts.portfolio_value:\n",
    "                maxp=max(maxp, i)\n",
    "                maxd= max((maxp-i)/maxp * 100, maxd)\n",
    "\n",
    "            \n",
    "            ret = np.diff(ts.portfolio_value) / np.array(ts.portfolio_value[:-1])\n",
    "            sharpe = np.mean(ret) / np.std(ret) * np.sqrt(252)\n",
    "                \n",
    "            plt.plot(ts.portfolio_value)\n",
    "            dat = [\n",
    "                [\"Number of closed trades\", len(ts.entry)],\n",
    "                [\"Winning trades\", len(ts.trade_wise_profit)],\n",
    "                [\"Losing trades\", len(ts.trade_wise_loss)],\n",
    "                [\"Benchmark returns\", round(ts.benchmark_return, 2)],\n",
    "                [\"Win rate\", (round((len(ts.trade_wise_profit) / len(ts.entry)) * 100, 2)) if len(ts.entry) != 0 else 0],\n",
    "                [\"Largest win\", round(np.max(ts.trade_wise_profit), 2)],\n",
    "                [\"Average win\", round(np.mean(ts.trade_wise_profit), 2)],\n",
    "                [\"Largest loss\", round(np.min(ts.trade_wise_loss), 2)],\n",
    "                [\"Average loss\", round(np.mean(ts.trade_wise_loss), 2)],\n",
    "                [\"Maximum holding time\", round(np.max(ts.trade_wise_duration), 2)],\n",
    "                [\"Average holding period\", round(np.mean(ts.trade_wise_duration), 2)],\n",
    "                #[\"Gross Profit\", round(ts.gross_profit, 2)],\n",
    "                [\"Net Profit\", round(ts.net_profit, 2)],\n",
    "                [\"Returns\", f\"{round(ts.returns, 2)} %\"],\n",
    "                [\"Sharpe\", f\"{sharpe}\"],\n",
    "                [\"Drawdown\", f\"{maxd}\"]\n",
    "            ]\n",
    "    \n",
    "            # Calculate the maximum length of the second column (Value column)\n",
    "            max_len_metric = max(len(row[0]) for row in dat)\n",
    "    \n",
    "            # Pad both columns based on the maximum length\n",
    "            padded_dat = [[row[0].ljust(max_len_metric), str(row[1]).rjust(10)] for row in dat]\n",
    "    \n",
    "            # Specify the table format, for example, \"grid\", \"pipe\", \"html\", \"latex\", etc.\n",
    "            table_format = \"grid\"\n",
    "    \n",
    "            # Print the table\n",
    "            print(tabulate(padded_dat, headers=[\"Metric\", \"Value\"], tablefmt=table_format))\n",
    "        except Exception as e:\n",
    "            print(\"ERROR IN PRINT_PARAMETERS\", e)\n",
    "            dat = [[str(sharpe), str(e)]]\n",
    "        return dat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bcc523-50be-4613-9188-7f83c1949e12",
   "metadata": {},
   "source": [
    "### FINDING ICHIMOKU PARAMETERS FOR VOLATILITY CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a0d34d-fa2b-4e8c-972c-7b4f096d0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ichimoku(data_comb):\n",
    "    high_9 = data_comb['High'].rolling(window=9).max()\n",
    "    low_9 = data_comb['Low'].rolling(window=9).min()\n",
    "    tenkan_sen = (high_9 + low_9) / 2\n",
    "    \n",
    "    high_26 = data_comb['High'].rolling(window=26).max()\n",
    "    low_26 = data_comb['Low'].rolling(window=26).min()\n",
    "    kijun_sen = (high_26 + low_26) / 2\n",
    "    \n",
    "    senkou_span_a = ((tenkan_sen + kijun_sen) / 2).shift(26)\n",
    "    senkou_span_b = ((high_52 := data_comb['High'].rolling(window=52).max()) + (low_52 := data_comb['Low'].rolling(window=52).min())) / 2\n",
    "    senkou_span_b = senkou_span_b.shift(26)\n",
    "    \n",
    "    chikou_span = data_comb['Close'].shift(-26)\n",
    "    \n",
    "    ema_12 = data_comb['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = data_comb['Close'].ewm(span=26, adjust=False).mean()\n",
    "    macd = ema_12 - ema_26\n",
    "    macd_signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    bullish = (data_comb['Close'] > senkou_span_a) & (data_comb['Close'] > senkou_span_b) & (tenkan_sen > kijun_sen) & (macd > macd_signal)\n",
    "    bearish = (data_comb['Close'] < senkou_span_a) & (data_comb['Close'] < senkou_span_b) & (tenkan_sen < kijun_sen) & (macd < macd_signal)\n",
    "    sideways = ~(bullish | bearish)\n",
    "    \n",
    "    data_comb['moment'] = np.where(bullish, 1, np.where(bearish, 0, 2))\n",
    "    \n",
    "    cloud_trace_a = go.Scatter(x=data_comb.index, y=senkou_span_a, mode='lines', name='Senkou Span A', line=dict(color='lightgreen'))\n",
    "    cloud_trace_b = go.Scatter(x=data_comb.index, y=senkou_span_b, mode='lines', name='Senkou Span B', line=dict(color='lightcoral'), fill='tonexty')\n",
    "    \n",
    "    bullish_trace = go.Scatter(x=data_comb.index, y=np.where(bullish, data_comb['Close'], np.nan), mode='lines', name='Bullish', line=dict(color='green'), opacity=0.5)\n",
    "    bearish_trace = go.Scatter(x=data_comb.index, y=np.where(bearish, data_comb['Close'], np.nan), mode='lines', name='Bearish', line=dict(color='red'), opacity=0.5)\n",
    "    sideways_trace = go.Scatter(x=data_comb.index, y=np.where(sideways, data_comb['Close'], np.nan), mode='lines', name='Sideways', line=dict(color='orange'), opacity=0.5)\n",
    "    \n",
    "    ichi = [cloud_trace_a, cloud_trace_b, bullish_trace, bearish_trace, sideways_trace]\n",
    "    return ichi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7e348-67fe-45e8-af58-a00eb15aef70",
   "metadata": {},
   "source": [
    "HELPER FUNCTION TO FETCH AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c38b080-e8d3-40cf-bf8d-70c1e6b2d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_newdata(data):\n",
    "    p = data.copy()\n",
    "    p['return'] = p['Close'].pct_change()\n",
    "    p['momentum'] = p['Close'] - p['Close'].shift(10)\n",
    "    p['short_ma'] = p['Close'].rolling(window=20).mean()\n",
    "    p['long_ma'] = p['Close'].rolling(window=50).mean()\n",
    "    p['trend'] = p['short_ma'] - p['long_ma']\n",
    "    p['volatility'] = p['Close'].rolling(window=26).std()\n",
    "    p['rsi'] = 100 - (100 / (1 + p['Close'].diff(1).apply(lambda x: max(x, 0)).rolling(window=14).mean() / p['Close'].diff(1).apply(lambda x: abs(min(x, 0))).rolling(window=14).mean()))\n",
    "    p['TR'] = np.maximum(p['High'] - p['Low'],\n",
    "                     np.maximum(abs(p['High'] - p['Close'].shift(1)),\n",
    "                                abs(p['Low'] - p['Close'].shift(1))))\n",
    "    p['ATR'] = p['TR'].rolling(window=14).mean()\n",
    "    p['atr']=p['TR'].rolling(window=14).mean()\n",
    "    p['upper_wick'] = p['High'] - p[['Open', 'Close']].max(axis=1)\n",
    "    p['lower_wick'] = p[['Open', 'Close']].min(axis=1) - p['Low']\n",
    "    p['wick_to_body'] = (p['upper_wick'] + p['lower_wick']) / (p['High']-p['Low'])\n",
    "    p['volume_spike'] = np.where(p['Volume'] > 1.5 * p['Volume'].rolling(window=20).mean(),1,0)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b8d02-868e-4da5-964a-67a1a0381122",
   "metadata": {},
   "source": [
    "### FETCH DATA USING YFINANCE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37541f30-42f3-4aab-bfd5-76757c13e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_data_back(ticker, sdate, edate):\n",
    "\n",
    "    date_str = sdate\n",
    "    date_obj = datetime.datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    new_date_obj = date_obj - relativedelta(years=1)\n",
    "    #import_date = new_date_obj.strftime(\"%Y-%m-%d\")\n",
    "    import_date= \"2017-01-01\"\n",
    "\n",
    "    if(new_date_obj<datetime.datetime.strptime(\"2017-01-01\", \"%Y-%m-%d\")):\n",
    "        print(\"Error please enter date after or equal to 2018-01-01 as 1 year past data is being used\")\n",
    "        return -1, -1\n",
    "    data_train = yf.download(ticker, import_date, sdate) # Open High Close Low Volume\n",
    "    data=yf.download(ticker,sdate,edate)\n",
    "    \n",
    "    vix_symbol = \"^VIX\"\n",
    "    \n",
    "    data_train.columns = data_train.columns.str.capitalize()\n",
    "    data.columns = data.columns.str.capitalize()\n",
    "    vix_data_t = yf.download(vix_symbol, import_date, sdate)\n",
    "    vix_data = yf.download(vix_symbol, sdate, edate)\n",
    "    data_train['VIX']=vix_data_t['Close']\n",
    "    data['VIX']=vix_data['Close']\n",
    "\n",
    "    data=gen_newdata(data)\n",
    "    data_train=gen_newdata(data_train)\n",
    "    data = data.dropna()\n",
    "    data_train = data_train.dropna()\n",
    "    return data_train, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531263c-edb2-456c-a668-84752242bd1e",
   "metadata": {},
   "source": [
    "### ICHIMOKU CLOUDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5df5ba-7942-4986-a96e-d94ff290eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ichimoku_clustering_analysis(df, n_clusters=3, column_mapping=None, ichimoku_weight=0.8, clustering_weight=0.2):\n",
    "    # Ensure the column mapping is provided\n",
    "    if column_mapping is None:\n",
    "        column_mapping = {\n",
    "            'High': 'High',\n",
    "            'Low': 'Low',\n",
    "            'Close': 'Close'\n",
    "        }\n",
    "\n",
    "    # Compute Ichimoku components\n",
    "    high_9 = df[column_mapping['High']].rolling(window=9).max()\n",
    "    low_9 = df[column_mapping['Low']].rolling(window=9).min()\n",
    "    tenkan_sen = (high_9 + low_9) / 2\n",
    "\n",
    "    high_26 = df[column_mapping['High']].rolling(window=26).max()\n",
    "    low_26 = df[column_mapping['Low']].rolling(window=26).min()\n",
    "    kijun_sen = (high_26 + low_26) / 2\n",
    "\n",
    "    senkou_span_a = ((tenkan_sen + kijun_sen) / 2).shift(26)\n",
    "    high_52 = df[column_mapping['High']].rolling(window=52).max()\n",
    "    low_52 = df[column_mapping['Low']].rolling(window=52).min()\n",
    "    senkou_span_b = ((high_52 + low_52) / 2).shift(26)\n",
    "\n",
    "    ema_12 = df[column_mapping['Close']].ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = df[column_mapping['Close']].ewm(span=26, adjust=False).mean()\n",
    "    macd = ema_12 - ema_26\n",
    "    macd_signal = macd.ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    \n",
    "    bullish = (df[column_mapping['Close']] > senkou_span_a) & (df[column_mapping['Close']] > senkou_span_b) & (tenkan_sen > kijun_sen) & (macd > macd_signal)\n",
    "    bearish = (df[column_mapping['Close']] < senkou_span_a) & (df[column_mapping['Close']] < senkou_span_b) & (tenkan_sen < kijun_sen) & (macd < macd_signal)\n",
    "    sideways = ~(bullish | bearish)\n",
    "\n",
    "    trend_classification_ichimoku = np.where(bullish, 1, np.where(bearish, 0, 2))\n",
    "\n",
    "    \n",
    "    p = df.copy()\n",
    "    \"\"\"\n",
    "    p['return'] = p['Close'].pct_change()  # Price returns\n",
    "    p['momentum'] = p['Close'] - p['Close'].shift(10)  # Momentum over 10 days\n",
    "    p['short_ma'] = p['Close'].rolling(window=20).mean()  # 20-day moving average\n",
    "    p['long_ma'] = p['Close'].rolling(window=50).mean()  # 50-day moving average\n",
    "    p['trend'] = p['short_ma'] - p['long_ma']  # Trend difference\n",
    "    p['volatility'] = p['Close'].rolling(window=26).std()  # Volatility\n",
    "    p['rsi'] = 100 - (100 / (1 + p['Close'].diff(1).apply(lambda x: max(x, 0)).rolling(window=14).mean() / p['Close'].diff(1).apply(lambda x: abs(min(x, 0))).rolling(window=14).mean()))  # RSI\n",
    "    p['VIX']=vix_data['Close']\n",
    "    p['TR'] = np.maximum(p['High'] - p['Low'],\n",
    "                     np.maximum(abs(p['High'] - p['Close'].shift(1)),\n",
    "                                abs(p['Low'] - p['Close'].shift(1))))\n",
    "    p['ATR'] = p['TR'].rolling(window=14).mean()\n",
    "    p['upper_wick'] = p['High'] - p[['Open', 'Close']].max(axis=1)\n",
    "    p['lower_wick'] = p[['Open', 'Close']].min(axis=1) - p['Low']\n",
    "    p['wick_to_body'] = (p['upper_wick'] + p['lower_wick']) / (p['High']-p['Low'])\n",
    "    p['volume_spike'] = np.where(p['Volume'] > 1.5 * p['Volume'].rolling(window=20).mean(),1,0)\n",
    "    \"\"\"\n",
    "\n",
    "    # FEATURES BEING USED FOR CLUSTERING 6x\n",
    "    features = np.column_stack([df['VIX'].fillna(0), df['wick_to_body'].fillna(0), df['trend'].fillna(0), df['ATR'].fillna(0), df['rsi'].fillna(50),df['volume_spike'].fillna(df['volume_spike'].mean()) ])\n",
    "\n",
    "    features = np.array(features, dtype=np.float64)\n",
    "\n",
    "    features = np.nan_to_num(features)\n",
    "\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # features_scaled = scaler.fit_transform(features)\n",
    "    features_scaled = (features)\n",
    "\n",
    "    # TimeSeriesKMeans Clustering\n",
    "    model = TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", max_iter=20, n_init=5)\n",
    "    model.fit(features_scaled)\n",
    "    p['trend_cluster'] = model.labels_\n",
    "\n",
    "    # Assign clusters to different trends\n",
    "    p_1 = p[p['trend_cluster'] == 0]\n",
    "    p_2 = p[p['trend_cluster'] == 1]\n",
    "    p_3 = p[p['trend_cluster'] == 2]\n",
    "    #p_4 = p[p['trend_cluster'] == 3]\n",
    "    #p_5 = p[p['trend_cluster'] == 4]\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.scatter(p_1.index.values, p_1['Close'], color='red', label='1')\n",
    "    plt.scatter(p_2.index.values, p_2['Close'], color='green', label='2')\n",
    "    plt.scatter(p_3.index.values, p_3['Close'], color='yellow', label='3')\n",
    "    #plt.scatter(p_4.index.values, p_4['Close'], color='blue', label='4')\n",
    "    #plt.scatter(p_5.index.values, p_5['Close'], color='black', label='5')\n",
    "\n",
    "\n",
    "     # Time Series Clustering\n",
    "    model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", verbose=False, random_state=42)\n",
    "    clusters = model.fit_predict(features)\n",
    "\n",
    "    x = df.index \n",
    "    y = clusters\n",
    "\n",
    "    # Now plotting\n",
    "    plt.scatter(x, y, c=y, cmap='viridis') \n",
    "    plt.title('Clustering of Reliance Stock Price into Bearish, Bullish, and Sideways Trends')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cluster Labels')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculating the weighted average trend classification (ichi+dtw)\n",
    "    trend_classification = (ichimoku_weight * trend_classification_ichimoku + clustering_weight * clusters).round().astype(int)\n",
    "    \n",
    "    barycenters = model.cluster_centers_\n",
    "    return clusters, barycenters,scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c30f5-4340-4763-8f63-55518ab1a1e7",
   "metadata": {},
   "source": [
    "### INTEGRATING THE CLUSTERING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540d895d-b4ad-4612-9fe3-a9e8db3ca77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_majority_vote(arr, segment_length=20, threshold=0.7):\n",
    "\n",
    "    segmented_arr = np.copy(arr)\n",
    "\n",
    "    for i in range(0, len(arr), segment_length):\n",
    "        # Extract the current segment (window_len sized)\n",
    "        segment = arr[i:i + segment_length]\n",
    "\n",
    "        # Find the majority group in the segment\n",
    "        values, counts = np.unique(segment, return_counts=True)\n",
    "        max_count = np.max(counts)\n",
    "        majority_value = values[np.argmax(counts)]\n",
    "\n",
    "        # Check if the majority value exceeds the threshold\n",
    "        if max_count / len(segment) >= threshold:\n",
    "            # Set all elements in the segment to the majority value\n",
    "            segmented_arr[i:i + segment_length] = majority_value\n",
    "\n",
    "    return segmented_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e4db1b-bfe7-4291-8b94-9597bd4a7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trendpart(data,start_date,end_date):\n",
    "\n",
    "    trend,centers,scaler=ichimoku_clustering_analysis(data, n_clusters=3, column_mapping=None, ichimoku_weight=0.5, clustering_weight=0.5)\n",
    "\n",
    "\n",
    "    final_trend=segment_and_majority_vote(trend)\n",
    "    data['cluster']=final_trend\n",
    "    \n",
    "    return data,centers,scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab11a8-ab4d-46cf-a15c-4eb12e4b56bf",
   "metadata": {},
   "source": [
    "### STRATEGY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8d9cde-3def-4c70-8777-9654a84c6ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat1(data):\n",
    "    df=data.copy()\n",
    "    def identify_support_resistance(df, window=7):\n",
    "        df['rolling_min'] = df['Low'].rolling(window=window).min()\n",
    "        df['rolling_max'] = df['High'].rolling(window=window).max()\n",
    "        df['support'] = df['rolling_min']\n",
    "        df['resistance'] = df['rolling_max']\n",
    "        return df\n",
    "\n",
    "# Function to generate buy/sell signals based on support and resistance levels\n",
    "    def generate_signals(df):\n",
    "        df['signals'] = 0  # Default no position\n",
    "        import numpy as np\n",
    "        # Buy when price is near support, Sell when price is near resistance\n",
    "        df['signals'] = np.where(df['Close'] <= df['support'], 1, df['signals'])  # Buy\n",
    "        df['signals'] = np.where(df['Close'] >= df['resistance'], -1, df['signals'])  # Sell\n",
    "        \n",
    "        return df\n",
    "    def heikin_Ashi(data):\n",
    "        data['Close_Ha'] = (data['Open'] + data['High'] + data['Close'] + data['Low']) / 4\n",
    "        data['Open_Ha'] = (data['Open'].shift(1) + data['Close'].shift(1)) / 2\n",
    "        data['High_Ha'] = data[['High', 'Close_Ha', 'Open_Ha']].max(axis=1)\n",
    "        data['Low_Ha'] = data[['Low', 'Close_Ha', 'Open_Ha']].min(axis=1)\n",
    "        return data\n",
    "    \n",
    "    # Technical Indicators\n",
    "    def RSI(df, period=14):\n",
    "        delta = df['Close_Ha'].diff(1)\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "        avg_gain = gain.rolling(window=period).mean()\n",
    "        avg_loss = loss.rolling(window=period).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "    \n",
    "    def calculate_sma(data, window):\n",
    "        return data.rolling(window=window).mean()\n",
    "    \n",
    "    def calculate_ema(data, window):\n",
    "        return data.ewm(span=window, adjust=False).mean()\n",
    "    \n",
    "    def OBV(df):\n",
    "        OBV = [0]\n",
    "        for i in range(1, len(df)):\n",
    "            if df['Close_Ha'][i] > df['Close_Ha'][i-1]:\n",
    "                OBV.append(OBV[-1] + df['Volume'][i])\n",
    "            elif df['Close_Ha'][i] < df['Close_Ha'][i-1]:\n",
    "                OBV.append(OBV[-1] - df['Volume'][i])\n",
    "            else:\n",
    "                OBV.append(OBV[-1])\n",
    "        return OBV\n",
    "\n",
    "    data = heikin_Ashi(data)\n",
    "    data['RSI'] = RSI(data)\n",
    "    data['OBV'] = OBV(data)\n",
    "    data['SMA'] = calculate_sma(data['Close_Ha'], 5)\n",
    "    data['EMA'] = calculate_ema(data['Close_Ha'], 5)\n",
    "    def strategy(data):\n",
    "        signals = []\n",
    "        for i in range(len(data)):\n",
    "            if(data['RSI'].iloc[i]<=39 and data['Close'].iloc[i]<=data['SMA'].iloc[i] and data['OBV'].iloc[i]>=data['OBV'].iloc[i-1]):\n",
    "                signals.append(1)\n",
    "            elif(data['RSI'].iloc[i]>=69 and data['Close'].iloc[i]>=data['SMA'].iloc[i] and data['OBV'].iloc[i]<=data['OBV'].iloc[i-1]):\n",
    "                signals.append(-1)\n",
    "            else:\n",
    "                signals.append(0)\n",
    "        return signals\n",
    "    #df = identify_support_resistance(df, window=10)\n",
    "\n",
    "    # Generate buy/sell signals\n",
    "    df = generate_signals(df)\n",
    "\n",
    "    data['signals']=strategy(data)\n",
    "    for i in range(len(data['signals'])):\n",
    "        if(data['signals'].iloc[i]==0 and df['signals'].iloc[i]==1):\n",
    "            data['signals'].iloc[i]=1\n",
    "        elif(data['signals'].iloc[i]==0 and df['signals'].iloc[i]==-1):\n",
    "            data['signals'].iloc[i]=-1\n",
    "    \n",
    "\n",
    "    #data['signals']=position\n",
    "    \n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12714d-cb4b-47a7-a99b-b0dddf91b76b",
   "metadata": {},
   "source": [
    "### STRATEGY 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a140814-e4ae-4f60-aebf-ca04a9d022bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat2(data):\n",
    "    df=data\n",
    "    df.index = pd.to_datetime(df.index, utc=False)\n",
    "\n",
    "    def calculate_huma(df, short_window=12, long_window=26, signal_window=9):\n",
    "        df['hma_short'] = df['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "        df['hma_long'] = df['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "        df['huma'] = df['hma_short'] - df['hma_long']\n",
    "        df['huma_line'] = df['huma'].ewm(span=signal_window, adjust=False).mean()\n",
    "        return df\n",
    "    \n",
    "    df = calculate_huma(df)\n",
    "\n",
    "# Calculate Chaikin Volatility\n",
    "    def calculate_chaikin_volatility(df, ema_period=14):\n",
    "        high_low_diff = df['High'] - df['Low']\n",
    "        ema_diff = high_low_diff.ewm(span=ema_period, adjust=False).mean()\n",
    "        chaikin_volatility = (ema_diff.diff() / ema_diff.shift(1)) * 100\n",
    "        df['Chaikin_Volatility'] = chaikin_volatility\n",
    "        return df\n",
    "\n",
    "    df = calculate_chaikin_volatility(df)\n",
    "\n",
    "# Calculate MFI (Money Flow Index)\n",
    "    def calculate_mfi(df, period):\n",
    "        tp = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "        mf = tp * df['Volume']\n",
    "        pos_mf = mf.where(tp > tp.shift(1), 0).rolling(window=period).sum()\n",
    "        neg_mf = mf.where(tp < tp.shift(1), 0).rolling(window=period).sum()\n",
    "        mf_ratio = pos_mf / neg_mf\n",
    "        return 100 - (100 / (1 + mf_ratio))\n",
    "\n",
    "    def dynamic_mfi(df):\n",
    "        # Calculate both short-term and long-term MFI\n",
    "        df['MFI_Short'] = calculate_mfi(df, period=9)\n",
    "        df['MFI_Long'] = calculate_mfi(df, period=14)\n",
    "    \n",
    "        # Determine which MFI to use based on Chaikin Volatility\n",
    "        mean_volatility = df['Chaikin_Volatility'].mean()\n",
    "        df['MFI'] = np.where(df['Chaikin_Volatility'] > mean_volatility, df['MFI_Short'], df['MFI_Long'])\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def calculate_ibs(df):\n",
    "    \n",
    "        ibs = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "        return ibs\n",
    "\n",
    "    df['IBS'] = calculate_ibs(df)\n",
    "    \n",
    "    df = dynamic_mfi(df)\n",
    "\n",
    "    # Calculate ADX (Average Directional Index)\n",
    "    def calculate_adx(df, period=14):\n",
    "        df['TR'] = np.maximum(df['High'] - df['Low'],\n",
    "                              np.maximum(abs(df['High'] - df['Close'].shift(1)),\n",
    "                                         abs(df['Low'] - df['Close'].shift(1))))\n",
    "        df['+DM'] = np.where((df['High'] - df['High'].shift(1)) > (df['Low'].shift(1) - df['Low']),\n",
    "                             np.maximum(df['High'] - df['High'].shift(1), 0), 0)\n",
    "        df['-DM'] = np.where((df['Low'].shift(1) - df['Low']) > (df['High'] - df['High'].shift(1)),\n",
    "                             np.maximum(df['Low'].shift(1) - df['Low'], 0), 0)\n",
    "        df['TR_smooth'] = df['TR'].rolling(window=period).mean()\n",
    "        df['+DI'] = 100 * (df['+DM'].rolling(window=period).mean() / df['TR_smooth'])\n",
    "        df['-DI'] = 100 * (df['-DM'].rolling(window=period).mean() / df['TR_smooth'])\n",
    "        df['DX'] = 100 * abs(df['+DI'] - df['-DI']) / (df['+DI'] + df['-DI'])\n",
    "        df['ADX'] = df['DX'].rolling(window=period).mean()\n",
    "        return df\n",
    "    \n",
    "    df = calculate_adx(df)\n",
    "\n",
    "    # Generate trade signals based on MACD, MFI, and ADX\n",
    "    df['Buy_Signal'] = np.where((df['huma'] < df['huma_line']) & (df['MFI'] < 30) & (df['ADX'] > 25), 1, 0)\n",
    "    df['Sell_Signal'] = np.where((df['huma'] > df['huma_line']) & (df['MFI'] > 70) & (df['ADX'] > 25), -1, 0)\n",
    "    \n",
    "    # Combine signals\n",
    "    df['signals'] = df['Buy_Signal'] + df['Sell_Signal']\n",
    "    def generate_signals(df):\n",
    "        df['signals'] = 0  # Default no position\n",
    "    \n",
    "        # Buy when price is near support, Sell when price is near resistance\n",
    "        df['signals'] = np.where(df['Close'] <= df['support'], 1, df['signals'])  # Buy\n",
    "        df['signals'] = np.where(df['Close'] >= df['resistance'], -1, df['signals'])  # Sell\n",
    "        \n",
    "        return df\n",
    "    df_cpy=df.copy()\n",
    "    df_cpy=generate_signals(df_cpy)\n",
    "    for i in range(len(df['Close'])):\n",
    "        if(df['signals'].iloc[i]==0 and df_cpy['signals'].iloc[i]==1):\n",
    "            df['signals'].iloc[i]=1\n",
    "        if(df['signals'].iloc[i]==0 and df_cpy['signals'].iloc[i]==-1):\n",
    "            df['signals'].iloc[i]=-1\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec04339-f820-47f3-a3d0-543ec1f68ab1",
   "metadata": {},
   "source": [
    "### STRATEGY 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c855bd-ba57-4e59-82c7-030084a0f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat3(data):\n",
    "    ## Signals based on cloud width\n",
    "    data_cpy=data.copy()\n",
    "    def Heiken_Ashi(df):\n",
    "        df['HA_close']=(df['Open']+ df['High']+ df['Low']+ df['Close'])/4\n",
    "        df['HA_open']=(df['Open']+df['Close'])/2\n",
    "    \n",
    "        for i in range(1, len(df)):\n",
    "            df['HA_open'][i]=(df['HA_open'][i-1]+df['HA_close'][i-1])/2\n",
    "            df['HA_high']=df[['HA_open','HA_close','High']].max(axis=1)\n",
    "            df['HA_low']=df[['HA_open','HA_close','Low']].min(axis=1)\n",
    "            df['Close']=df['HA_close']\n",
    "            df['Open']=df['HA_open']\n",
    "            df['High']=df['HA_high']\n",
    "            df['Low']=df['HA_low']\n",
    "        return df\n",
    "    data_cpy=Heiken_Ashi(data_cpy)\n",
    "    from numpy import nan as npnan\n",
    "    from numpy import log as npLog\n",
    "    from numpy import power as npPower\n",
    "    from numpy import sqrt as npSqrt\n",
    "    from numpy import zeros_like as npZeroslike\n",
    "    from pandas import Series\n",
    "    from pandas_ta.utils import get_offset, verify_series\n",
    "    from numpy import average as npAverage\n",
    "    def jma(close, length=None, phase=None, offset=None, **kwargs):\n",
    "        \"\"\"Indicator: Jurik Moving Average (JMA)\"\"\"\n",
    "        #This is a proprietary denoising algo that I searched for from internet\n",
    "        # Validate Arguments\n",
    "        _length = int(length) if length and length > 0 else 7\n",
    "        phase = float(phase) if phase and phase != 0 else 0\n",
    "        close = verify_series(close, _length)\n",
    "        offset = get_offset(offset)\n",
    "        if close is None: return\n",
    "    \n",
    "        # Define base variables\n",
    "        jma = npZeroslike(close)\n",
    "        volty = npZeroslike(close)\n",
    "        v_sum = npZeroslike(close)\n",
    "    \n",
    "        kv = det0 = det1 = ma2 = 0.0\n",
    "        jma[0] = ma1 = uBand = lBand = close[0]\n",
    "    \n",
    "        # Static variables\n",
    "        sum_length = 10\n",
    "        length = 0.5 * (_length - 1)\n",
    "        pr = 0.5 if phase < -100 else 2.5 if phase > 100 else 1.5 + phase * 0.01\n",
    "        length1 = max((npLog(npSqrt(length)) / npLog(2.0)) + 2.0, 0)\n",
    "        pow1 = max(length1 - 2.0, 0.5)\n",
    "        length2 = length1 * npSqrt(length)\n",
    "        bet = length2 / (length2 + 1)\n",
    "        beta = 0.45 * (_length - 1) / (0.45 * (_length - 1) + 2.0)\n",
    "    \n",
    "        m = close.shape[0]\n",
    "        for i in range(1, m):\n",
    "            price = close[i]\n",
    "    \n",
    "            # Price volatility\n",
    "            del1 = price - uBand\n",
    "            del2 = price - lBand\n",
    "            volty[i] = max(abs(del1),abs(del2)) if abs(del1)!=abs(del2) else 0\n",
    "    \n",
    "            # Relative price volatility factor\n",
    "            v_sum[i] = v_sum[i - 1] + (volty[i] - volty[max(i - sum_length, 0)]) / sum_length\n",
    "            avg_volty = npAverage(v_sum[max(i - 65, 0):i + 1])\n",
    "            d_volty = 0 if avg_volty ==0 else volty[i] / avg_volty\n",
    "            r_volty = max(1.0, min(npPower(length1, 1 / pow1), d_volty))\n",
    "    \n",
    "            # Jurik volatility bands\n",
    "            pow2 = npPower(r_volty, pow1)\n",
    "            kv = npPower(bet, npSqrt(pow2))\n",
    "            uBand = price if (del1 > 0) else price - (kv * del1)\n",
    "            lBand = price if (del2 < 0) else price - (kv * del2)\n",
    "    \n",
    "            # Jurik Dynamic Factor\n",
    "            power = npPower(r_volty, pow1)\n",
    "            alpha = npPower(beta, power)\n",
    "    \n",
    "            # 1st stage - prelimimary smoothing by adaptive EMA\n",
    "            ma1 = ((1 - alpha) * price) + (alpha * ma1)\n",
    "    \n",
    "            # 2nd stage - one more prelimimary smoothing by Kalman filter\n",
    "            det0 = ((price - ma1) * (1 - beta)) + (beta * det0)\n",
    "            ma2 = ma1 + pr * det0\n",
    "    \n",
    "            # 3rd stage - final smoothing by unique Jurik adaptive filter\n",
    "            det1 = ((ma2 - jma[i - 1]) * (1 - alpha) * (1 - alpha)) + (alpha * alpha * det1)\n",
    "            jma[i] = jma[i-1] + det1\n",
    "    \n",
    "        # Remove initial lookback data and convert to pandas frame\n",
    "        jma[0:_length - 1] = npnan\n",
    "        jma = Series(jma, index=close.index)\n",
    "    \n",
    "        # Offset\n",
    "        if offset != 0:\n",
    "            jma = jma.shift(offset)\n",
    "    \n",
    "        # Handle fills\n",
    "        if \"fillna\" in kwargs:\n",
    "            jma.fillna(kwargs[\"fillna\"], inplace=True)\n",
    "        if \"fill_method\" in kwargs:\n",
    "            jma.fillna(method=kwargs[\"fill_method\"], inplace=True)\n",
    "    \n",
    "        # Name & Category\n",
    "        jma.name = f\"JMA_{_length}_{phase}\"\n",
    "        jma.category = \"overlap\"\n",
    "    \n",
    "        return jma\n",
    "    \n",
    "    data_cpy['jma']=jma(data_cpy['Close'],7)\n",
    "    def calculate_weighted_avg(data, span=5):\n",
    "    \n",
    "        data['Upward_price_movement'] = data['Close'] - data['Low']\n",
    "        data['Candle_length'] = data['High'] - data['Low']\n",
    "        data['IBS'] = data['Upward_price_movement'] / data['Candle_length']\n",
    "        data['weight_avg'] = data['IBS'].ewm(span=span, adjust=False).mean()\n",
    "        return data\n",
    "    \n",
    "    data_cpy = calculate_weighted_avg(data_cpy)\n",
    "    def hma(data,period):\n",
    "         data['sma_5'] = data['Close'].ewm(span=5,adjust=False).mean()\n",
    "         wma_1 = data['Close'].rolling(period//2).apply(lambda x: \\\n",
    "         np.sum(x * np.arange(1, period//2+1)) / np.sum(np.arange(1, period//2+1)), raw=True)\n",
    "         wma_2 = data['Close'].rolling(period).apply(lambda x: \\\n",
    "         np.sum(x * np.arange(1, period+1)) / np.sum(np.arange(1, period+1)), raw=True)\n",
    "         diff = 2 * wma_1 - wma_2\n",
    "         hma = diff.rolling(int(np.sqrt(period))).mean()\n",
    "         data['hma'] = hma\n",
    "         return data\n",
    "\n",
    "\n",
    "    data_cpy = hma(data_cpy, 15)\n",
    "    def atr(data):\n",
    "      period = 20\n",
    "    \n",
    "      data['TR'] = 0\n",
    "    \n",
    "      for i in range(1, len(data)):\n",
    "          high_low_range = abs(data['High'][i] - data['Low'][i])  # High-Low Range\n",
    "          high_prev_close_range = abs(data['High'][i] - data['Close'][i - 1])  # High-Previous Close Range\n",
    "          low_prev_close_range = abs(data['Low'][i] - data['Close'][i - 1])  # Low-Previous Close Range\n",
    "    \n",
    "          # Assign the maximum value of the three ranges to the 'TR' column for the current row\n",
    "          data['TR'][i] = max(high_low_range, high_prev_close_range, low_prev_close_range)\n",
    "      data['atr'] = 0\n",
    "      data['atr'] = data['TR'].rolling(window=period).mean()\n",
    "      data['signal_atr']=data['atr'].ewm(span=25).mean()  #ewm check\n",
    "    \n",
    "      data['slope_atr']=(data['signal_atr']-data['signal_atr'].shift(10))/10\n",
    "    \n",
    "      return data\n",
    "    \n",
    "    data_cpy=atr(data_cpy)\n",
    "    data=atr(data)\n",
    "    def Elder_Ray(data,ema_period=13):\n",
    "        data['EMA'] = data['Close'].ewm(span=ema_period, adjust=False).mean()\n",
    "    \n",
    "        # Calculate Bull Power\n",
    "        data['Bull Power'] = data['High'] - data['EMA']\n",
    "    \n",
    "        # Calculate Bear Power\n",
    "        data['Bear Power'] = data['Low'] - data['EMA']\n",
    "        return data\n",
    "    \n",
    "    data_cpy=Elder_Ray(data_cpy)\n",
    "    def self_strat(data):\n",
    "      #WHEN HIGH STANDARD DEVIATION TAKE TRADES\n",
    "      a=np.where(data['Close'].rolling(window=5).std()>0.7,1,0)\n",
    "      #WHEN LOW STANDARD DEVIATION TAKE TRADES\n",
    "      b=np.where(data['Close'].rolling(window=5).std()<0.3,-1,0)\n",
    "      data['self_signals']=a+b\n",
    "      x=data['Close'].rolling(window=10).std()\n",
    "      y=x.ewm(span=5).mean()\n",
    "      z=x.rolling(window=5).mean()\n",
    "      data['self_signals_2']=np.where(y>z,1,-1)\n",
    "      data['sma_10']=data['Close'].rolling(window=10).mean()\n",
    "      data['ema_10']=data['Close'].ewm(span=10,adjust=False).mean()\n",
    "      data['sma_5']=data['Close'].rolling(window=5).mean()\n",
    "      data['ewm_5']=data['Close'].ewm(span=5,adjust=False).mean()\n",
    "      data['h_l']=data['High']-data['Low']\n",
    "      z=data['h_l'].rolling(window=5).std()\n",
    "      data['self_signals_3']=np.where(z>0.3,1,-1)\n",
    "      return data\n",
    "    data_cpy=self_strat(data_cpy)\n",
    "    def calculate_macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "        data['EMA12'] = data['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "        data['EMA26'] = data['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "        data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "        data['Signal'] = data['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    data_cpy['macd_signals'] = 0\n",
    "    data_cpy=calculate_macd(data_cpy)\n",
    "    # Generate signals based on the MACD line and Signal line crossovers\n",
    "    data_cpy['macd_signals'][1:] = np.where(data_cpy['MACD'][1:] > data_cpy['Signal'][1:], 1, 0)\n",
    "    data_cpy['macd_signals'][1:] = np.where(data_cpy['MACD'][1:] < data_cpy['Signal'][1:], -1, data_cpy['macd_signals'][1:])\n",
    "    from ta.trend import ADXIndicator\n",
    "    def include_adx(df , di_period , adx_period):\n",
    "        adxI = ADXIndicator(df['High'] , df['Low'] , df['Close'] ,20)\n",
    "        df['pos_directional_indicator'] = adxI.adx_pos()\n",
    "        df['neg_directional_indicator'] = adxI.adx_neg()\n",
    "        df['adx'] = adxI.adx()\n",
    "        #df['+di'] = ta.PLUS_DI(df['high'] , df['ha_low'] , df['close'] , timeperiod= di_period)\n",
    "        #df['-di'] = ta.MINUS_DI(df['high'] , df['low'] , df['close'] , timeperiod= di_period)\n",
    "        return df\n",
    "    \n",
    "    data_cpy=include_adx(data_cpy,14,30)\n",
    "    data_cpy['signals'] = 0\n",
    "    for i in range(1, len(data_cpy)):\n",
    "\n",
    "        if    ( ((data_cpy['hma'][i] > data_cpy['sma_5'][i] )   and\n",
    "                 (data_cpy['weight_avg'][i] >= 0.6) and\n",
    "                    ((data_cpy['macd_signals'].iloc[i]==1) and\n",
    "                    (data_cpy['atr'].iloc[i]>data_cpy['signal_atr'].iloc[i] and data_cpy['slope_atr'].iloc[i]>0 ) and\n",
    "                    ( data_cpy['Bull Power'][i]>1.2  )\n",
    "                ) )  or ((data_cpy['Close'][i]<data_cpy['sma_10'][i] and data_cpy['self_signals'][i]==1 and data_cpy['Bull Power'][i]>1.2 and data_cpy['ema_10'][i]>data_cpy['sma_10'][i] ))\n",
    "              ):\n",
    "            # Set signal to 1 for a bullish signal\n",
    "            data_cpy.signals[i] = 1\n",
    "    \n",
    "        # Check if conditions for a bearish signal are met\n",
    "        if ( ((data_cpy['hma'][i] < data_cpy['sma_5'][i] ) and\n",
    "                    (\n",
    "                         (data_cpy['weight_avg'][i] <= 0.38) and\n",
    "                        (data_cpy['macd_signals'].iloc[i]==-1) and\n",
    "                    (data_cpy['atr'].iloc[i]<data_cpy['signal_atr'].iloc[i] and data_cpy['slope_atr'].iloc[i]<0  ) and\n",
    "                    (data_cpy['Bear Power'][i]<-1.2)\n",
    "    \n",
    "                       ) ) \n",
    "                       or (data_cpy['Close'][i]>data_cpy['sma_10'][i] and data_cpy['self_signals'][i]==-1 and data_cpy['Bear Power'][i]<-1.2 and data_cpy['ema_10'][i]<data_cpy['sma_10'][i] )\n",
    "                       ):\n",
    "            # Set signal to -1 for a bearish signal\n",
    "            data_cpy.signals[i] = -1\n",
    "    df=data.copy()\n",
    "    #df=data.copy()\n",
    "    def identify_support_resistance(df, window=4):\n",
    "        df['rolling_min'] = df['Low'].rolling(window=window).min()\n",
    "        df['rolling_max'] = df['High'].rolling(window=window).max()\n",
    "        df['support'] = df['rolling_min']\n",
    "        df['resistance'] = df['rolling_max']\n",
    "        return df\n",
    "\n",
    "    # Function to generate buy/sell signals based on support and resistance levels\n",
    "    def generate_signals(df):\n",
    "        df['signals'] = 0  # Default no position\n",
    "    \n",
    "        # Buy when price is near support, Sell when price is near resistance\n",
    "        df['signals'] = np.where(df['Close'] <= df['support'], 1, df['signals'])  # Buy\n",
    "        df['signals'] = np.where(df['Close'] >= df['resistance'], -1, df['signals'])  # Sell\n",
    "        \n",
    "        return df\n",
    "    #df = identify_support_resistance(df, window=4)\n",
    "\n",
    "    # Generate buy/sell signals\n",
    "    df = generate_signals(df)\n",
    "    for i in range(len(data_cpy['signals'])):\n",
    "        if(data_cpy['signals'].iloc[i]==0 and df['signals'].iloc[i]==1):\n",
    "            data_cpy['signals'].iloc[i]=1\n",
    "        elif(data_cpy['signals'].iloc[i]==0 and df['signals'].iloc[i]==-1):\n",
    "            data_cpy['signals'].iloc[i]=-1\n",
    "    \n",
    "    data['signals']=data_cpy['signals']\n",
    "    #data=data.rename(columns={'open':'Open','close':'Close','high':'High','low':'Low'})\n",
    "                \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63640658-1e60-4f8b-9fe4-b3c2e6321206",
   "metadata": {},
   "source": [
    "### STRATEGY 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c58c23-3084-46b9-a0d3-2fa60b3d5792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Buy Signal: When a Heikin-Ashi candle changes from red to green, and the volume is significantly higher than the average volume over the last 10 periods.\n",
    "Sell Signal: When a Heikin-Ashi candle changes from green to red, and the volume is significantly higher than the average volume over the last 10 periods.\n",
    "\"\"\"\n",
    "def strat4(data):\n",
    "    data['HA_Close'] = (data['Open'] + data['High'] + data['Low'] + data['Close']) / 4\n",
    "    data['HA_Open'] = (data['Open'].shift(1) + data['Close'].shift(1)) / 2\n",
    "    data['HA_High'] = data[['High', 'HA_Open', 'HA_Close']].max(axis=1)\n",
    "    data['HA_Low'] = data[['Low', 'HA_Open', 'HA_Close']].min(axis=1)\n",
    "    \n",
    "    data['Avg_Volume'] = data['Volume'].rolling(window=10).mean()\n",
    "    data['Volume_Spike'] = data['Volume'] > data['Avg_Volume'] * 1.5\n",
    "    \n",
    "    data['signals'] = 0\n",
    "    data.loc[(data['HA_Close'] > data['HA_Open']) & (data['HA_Close'].shift(1) <= data['HA_Open'].shift(1)) & data['Volume_Spike'], 'signals'] = 1\n",
    "    data.loc[(data['HA_Close'] < data['HA_Open']) & (data['HA_Close'].shift(1) >= data['HA_Open'].shift(1)) & data['Volume_Spike'], 'signals'] = -1\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ce947-7f6f-47ba-9fb0-8202241deb75",
   "metadata": {},
   "source": [
    "### RISK MANAGEMENT - ATR BASED STOP-LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f4751a7-47cf-46d3-952c-504deb91e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATR_SL(data,data_cpy,signal, strategynum): # ATR BASED SL takes   df, df+cpy, snum -> modifies df.signals inplace\n",
    "    type_trade=0  # 1-> long -1->short  0->const\n",
    "    signals=[]\n",
    "    current_max=0\n",
    "    current_min=0\n",
    "    for i in range(len(data)-1):\n",
    "        if(type_trade==1):\n",
    "            if(signal.iloc[i]==0 or signal.iloc[i]==1):\n",
    "                if(data_cpy['Close'].iloc[i]>atr_take_profit or data_cpy['Close'].iloc[i]<atr_stop_loss):\n",
    "                    signals.append(-1)\n",
    "                    type_trade=0\n",
    "                else:\n",
    "                    signals.append(0)\n",
    "            else:\n",
    "                type_trade=0\n",
    "                signals.append(-1)\n",
    "\n",
    "        elif(type_trade==-1):\n",
    "            if(signal.iloc[i]==0 or signal.iloc[i]==-1):\n",
    "                if(data_cpy['Close'].iloc[i]<atr_take_profit or data_cpy['Close'].iloc[i]>atr_stop_loss):\n",
    "                    signals.append(1)\n",
    "                    type_trade=0\n",
    "                else:\n",
    "                    signals.append(0)\n",
    "            else:\n",
    "                type_trade=0\n",
    "                signals.append(1)\n",
    "        else:\n",
    "            if(signal.iloc[i]==1):\n",
    "                signals.append(1)\n",
    "                type_trade=1\n",
    "                if(strategynum==1):\n",
    "                    atr_stop_loss = data_cpy.Close[i] - data_cpy.atr[i]*0.1\n",
    "                    atr_take_profit=data_cpy.High_s[i] + data_cpy.atr[i]*1.5\n",
    "                elif(strategynum==2):\n",
    "                    atr_stop_loss = data_cpy.Low_s[i] - data_cpy.atr[i]*1.5\n",
    "                    atr_take_profit=data_cpy.High_s[i] + data_cpy.atr[i]*1.9\n",
    "                elif(strategynum==3):\n",
    "                    atr_stop_loss = data_cpy.Low_s[i] - data_cpy.atr[i]*2.0\n",
    "                    atr_take_profit=data_cpy.High_s[i] + data_cpy.atr[i]*2.7\n",
    "                else:\n",
    "                    print('What')\n",
    "                    atr_stop_loss = data_cpy.Low_s[i] - data_cpy.atr[i]*2.5\n",
    "                    atr_take_profit=data_cpy.High_s[i] + data_cpy.atr[i]*5\n",
    "            \n",
    "            elif(signal.iloc[i]==-1):\n",
    "                signals.append(-1)\n",
    "                type_trade=-1\n",
    "                if(strategynum==1):\n",
    "                    print('SL Hit strat1')\n",
    "                    atr_stop_loss = data_cpy.Close[i] + data_cpy.atr[i]*0.1\n",
    "                    atr_take_profit=data_cpy.Low_s[i] - data_cpy.atr[i]*1.5\n",
    "                elif(strategynum==2):\n",
    "                    atr_stop_loss = data_cpy.High_s[i] + data_cpy.atr[i]*1.5\n",
    "                    atr_take_profit=data_cpy.Low_s[i] - data_cpy.atr[i]*1.9\n",
    "                elif(strategynum==3):\n",
    "                    atr_stop_loss = data_cpy.High_s[i] + data_cpy.atr[i]*2.0\n",
    "                    atr_take_profit=data_cpy.Low_s[i] - data_cpy.atr[i]*2.7\n",
    "                else:\n",
    "                    print('What error')\n",
    "                    atr_stop_loss = data_cpy.High_s[i] + data_cpy.atr[i]*2.5\n",
    "                    atr_take_profit=data_cpy.Low_s[i] - data_cpy.atr[i]*5\n",
    "            else:\n",
    "                type_trade=0\n",
    "                signals.append(0)\n",
    "\n",
    "    if(type_trade==1):\n",
    "        signals.append(-1)\n",
    "    elif(type_trade==-1):\n",
    "        signals.append(1)\n",
    "    else:\n",
    "        signals.append(0)\n",
    "\n",
    "    data['signals']=signals\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80e11745-75c6-49fd-932a-6851c9d7e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_signals(data): # ensure only 1 active position\n",
    "    type_trade=0\n",
    "    for i in range(len(data)-1):\n",
    "        if(data['signals'].iloc[i]==1 and type_trade==1):\n",
    "            data['signals'].iloc[i]=0\n",
    "        elif(data['signals'].iloc[i]==-1 and type_trade==-1):\n",
    "            data['signals'].iloc[i]=0\n",
    "        elif((data['signals'].iloc[i]==1 or data['signals'].iloc[i]==-1) and type_trade==0):\n",
    "            type_trade=data['signals'].iloc[i]\n",
    "        elif(data['signals'].iloc[i]==1 and type_trade==-1):\n",
    "            type_trade=0\n",
    "        elif(data['signals'].iloc[i]==-1 and type_trade==1):\n",
    "            type_trade=0\n",
    "    if(type_trade==1):\n",
    "        data['signals'].iloc[len(data)-1]=-1\n",
    "    elif(type_trade==-1):\n",
    "        data['signals'].iloc[len(data)-1]==1\n",
    "    return data\n",
    "            \n",
    "    data[\"signals\"] = signals\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1510de1b-accd-4b58-8ce9-7c7384b7eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(categories, pool_size):\n",
    "    pooled_categories = []\n",
    "    \n",
    "    # Max pooling over the defined window size\n",
    "    for i in range(0, len(categories), pool_size):\n",
    "        segment = categories[i:i + pool_size]\n",
    "        max_cat = np.max(segment)\n",
    "        pooled_categories.extend([max_cat] * len(segment))\n",
    "    \n",
    "    return pooled_categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e771b-7050-48e8-b9ea-17212b3f0e70",
   "metadata": {},
   "source": [
    "### CLUSTER PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "961ed4aa-802c-4c9d-b792-074ed3464422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster(new_data, centers):\n",
    "    # Extract and preprocess features from new_data (similar to the training phase)\n",
    "    features = np.column_stack([\n",
    "        new_data['VIX'],\n",
    "        new_data['wick_to_body'],\n",
    "        new_data['trend'],\n",
    "        new_data['ATR'],\n",
    "        new_data['rsi'],\n",
    "        new_data['volume_spike']\n",
    "    ])\n",
    "    features=features.reshape(-1,1)\n",
    "    \n",
    "    features = np.array(features, dtype=np.float64)  \n",
    "    features = np.nan_to_num(features)\n",
    "    distances = [dtw(features, center) for center in centers]\n",
    "    predicted_cluster = np.argmin(distances)\n",
    "    return predicted_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "190fe312-f5c1-44df-8dee-fb068d920394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_category(data,centers,scaler):\n",
    "\n",
    "    predicted_cluster = predict_cluster(data, centers)\n",
    "    # print(f\"The new data point belongs to cluster: {predicted_cluster}\")\n",
    "    return predicted_cluster\n",
    "    \n",
    "        \n",
    "    # returns len data // windowlen sized array of category nums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d811ca-9181-4307-a701-9583a9e40a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calclen(data):\n",
    "    return min(len(data),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c269e1f1-6756-405e-8ba4-f6614472bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(tick, sdate, edate):\n",
    "    data_train, data = get_preprocessed_data_back(tick, sdate, edate)\n",
    "\n",
    "    if( type(data) == int ):\n",
    "        if(data == -1):\n",
    "            print(\"here\")\n",
    "            return None, None, None, None, \"Error please enter date after or equal to 2018-01-01 as 1 year past data is being used\"\n",
    "        \n",
    "\n",
    "    # fit model using data_train\n",
    "    # get insight\n",
    "    data_train, center, scaler = trendpart(data_train,sdate,edate) # data_train now has another colmn for category\n",
    "\n",
    "    window_len = calclen(data_train) ## implement this\n",
    "\n",
    "    pred_arr = []\n",
    "    for i in range(len(data)):\n",
    "        pred_arr.append(find_category(data.iloc[i],center,scaler))\n",
    "\n",
    "    data['category'] = 0\n",
    "    data['category']=pred_arr\n",
    "    #max pooling\n",
    "    data['category_pool']=max_pooling(data['category'],pool_size=20)\n",
    "\n",
    "    # shift category down by window_len to not use future value\n",
    "    window=7\n",
    "    data['category_pool']=data['category_pool'].shift(window_len)\n",
    "    data['rolling_min'] = data['Low'].rolling(window=window).min()\n",
    "    data['rolling_max'] = data['High'].rolling(window=window).max()\n",
    "    data['support'] = data['rolling_min']\n",
    "    data['resistance'] = data['rolling_max']\n",
    "\n",
    "    data['High_s']=data['Close'].rolling(window=15).max()\n",
    "    data['Low_s']=data['Close'].rolling(window=15).min()\n",
    "    \n",
    "    # now every category corresponds to correct close price\n",
    "    total_signals = []\n",
    "    current_win_sig = []\n",
    "    num_segments = len(data) // window_len\n",
    "    for seg_no in range(num_segments):\n",
    "        segment = data.iloc[seg_no * window_len: min(len(data),(seg_no + 1) * window_len)]\n",
    "        category = segment['category_pool'].iloc[0]  # Get the category of the current segment\n",
    "        if category == 0:\n",
    "            segment = strat1(segment)\n",
    "            segment=clean_signals(segment)\n",
    "            segment=ATR_SL(segment,segment,segment['signals'],1)\n",
    "            current_win_sig=segment['signals']\n",
    "            \n",
    "        elif category == 1:\n",
    "            segment = strat2(segment)\n",
    "            segment=clean_signals(segment)\n",
    "            segment=ATR_SL(segment,segment,segment['signals'],2)\n",
    "            current_win_sig=segment['signals']\n",
    "        elif category == 2:\n",
    "            segment = strat3(segment)\n",
    "            segment=clean_signals(segment)\n",
    "            segment=ATR_SL(segment,segment,segment['signals'],3)\n",
    "            current_win_sig=segment['signals']\n",
    "        elif category == 3:\n",
    "            segment = strat4(segment)\n",
    "            segment=clean_signals(segment)\n",
    "            segment=ATR_SL(segment,segment,segment['signals'],4)\n",
    "            current_win_sig=segment['signals']\n",
    "\n",
    "        # Ensure the signals are clean (preprocess within the strategy function or here)\n",
    "        total_signals.extend(current_win_sig)\n",
    "\n",
    "    # make length of toal_sigmals and data equal by appending 0s in total_signlas\n",
    "    if len(total_signals) < len(data):\n",
    "        total_signals.extend([0] * (len(data) - len(total_signals)))\n",
    "\n",
    "    # Assign the signals to the data\n",
    "    data[\"signals\"] = total_signals\n",
    "\n",
    "    data['low']=data['Low']\n",
    "    data['high']=data['High']\n",
    "    data['close']=data['Close']\n",
    "    data['open']=data['Open']\n",
    "    data['volume']=data['Volume']\n",
    "    data['datetime'] = data.index\n",
    "    \n",
    "    Testing_signals = TradingStrategy_Compounding(data)\n",
    "    to_submit_comp, tradewise, daily, graph, metricstr = Testing_signals.compounding()\n",
    "    \n",
    "    \n",
    "    # returnables = backtest(data, 1, 1, data[\"FinalSignals\"])  # Adjust the parameters as necessary\n",
    "    data['category_pool'] = data['category_pool'].fillna(0)\n",
    "    catarr = data['category_pool'].to_numpy()\n",
    "\n",
    "    tradewise['cluster'] = [catarr[i] for i in tradewise['entry']]\n",
    "    \n",
    "    daily['cluster'] = data['category_pool'].to_numpy()\n",
    "    return data, daily, tradewise, graph, metricstr\n",
    "    # df, daily, tradewise, graph, metricstr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a59edf-d1de-4c0e-9197-32e001235977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, dailydf, tradedf, f, metricstr=backtest_strategy(\"MSFT\",\"2017-01-01\",\"2018-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7c2600d-2e69-4bf6-af95-1a6e44bd7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_signals_fwd(data):\n",
    "    type_trade=0\n",
    "    for i in range(len(data)):\n",
    "        if(data['signals'].iloc[i]==1 and type_trade==1):\n",
    "            data['signals'].iloc[i]=0\n",
    "        elif(data['signals'].iloc[i]==-1 and type_trade==-1):\n",
    "            data['signals'].iloc[i]=0\n",
    "        elif((data['signals'].iloc[i]==1 or data['signals'].iloc[i]==-1) and type_trade==0):\n",
    "            type_trade=data['signals'].iloc[i]\n",
    "        elif(data['signals'].iloc[i]==1 and type_trade==-1):\n",
    "            type_trade=0\n",
    "        elif(data['signals'].iloc[i]==-1 and type_trade==1):\n",
    "            type_trade=0\n",
    "    data['signals']=data['signals']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3760e-af37-4c17-a367-af5681b418fe",
   "metadata": {},
   "source": [
    "### FORWARD TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eaad1cc-b9f5-4538-9911-e052ec719c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def forwardtest_strategy(data):\n",
    "    \n",
    "    data['SMA5'] = data['Close'].rolling(window=5).mean()\n",
    "    data['SMA20'] = data['Close'].rolling(window=20).mean()\n",
    "    \n",
    "    signals = np.where((data['SMA5'] > data['SMA20']) & (data['Close']), 1, -1)\n",
    "    data['signals'] = 0\n",
    "    data['signals'][5:] = signals[5:]\n",
    "\n",
    "    # signalsarray=random.shuffle([-1]*30+[1]*(len(data)-30))\n",
    "    # data['signal'] = signalsarray\n",
    "    \n",
    "    \n",
    "    data = clean_signals_fwd(data)\n",
    "    \n",
    "    returnables = backtest(data, 0.05, 0.001, data.FinalSignals)\n",
    "    return returnables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89435230-a85f-4021-a797-ee5f75477c4a",
   "metadata": {},
   "source": [
    " ### GRADIO CODE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5565930-1eca-47b5-84d2-4865741d3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_historical_results(df, daily, tradewise, graph):\n",
    "    #print(\"from plothistorical\", df)\n",
    "    fig1buy = pd.DataFrame()\n",
    "    fig1sell = pd.DataFrame()\n",
    "    print('df\\n',df)\n",
    "    daily.drop('Close',axis=1,inplace=True)\n",
    "    print('daily',daily)\n",
    "    daily['Close'] = df.Close.to_numpy()\n",
    "    print('daily',daily)\n",
    "    \n",
    "    for _, row in daily.iterrows():\n",
    "        if row['signals'] > 0:\n",
    "            print(\"plotting buy\")\n",
    "            new_row = pd.DataFrame({\"x\": [row['datetime']], \"y\": [row['Close']], \"type\": [\"buy\"]})\n",
    "            fig1buy = pd.concat([fig1buy, new_row], ignore_index=True)\n",
    "        elif row['signals'] < 0:\n",
    "            print(\"plotting sell\")\n",
    "            new_row = pd.DataFrame({\"x\": [row['datetime']], \"y\": [row['Close']], \"type\": [\"sell\"]})\n",
    "            fig1sell = pd.concat([fig1sell, new_row], ignore_index=True)\n",
    "\n",
    "    #  'g^', markersize=10\n",
    "    #  'rv', markersize=10\n",
    "    \n",
    "    \n",
    "    df1 = pd.DataFrame({\"x\": df.index, \"y\":df.Close, \"type\":\"line\"})\n",
    "    \n",
    "    df2 = pd.DataFrame({\"x\": df.index, \"y\":daily['portfolio value']})\n",
    "    \n",
    "    fig1 = go.Figure()\n",
    "    fig2=go.Figure()\n",
    "\n",
    "    fig1.add_trace(go.Scatter(x=df1[\"x\"], y=df1[\"y\"], mode='lines', name='ClosePrice'))\n",
    "    fig2.add_trace(go.Scatter(x=df2[\"x\"], y=df2[\"y\"], mode='lines', name='Portfolio'))\n",
    "\n",
    "    print(\"plotting fig1buysell  \",fig1buy, fig1sell)\n",
    "    \n",
    "    fig1.add_trace(go.Scatter(x=fig1buy[\"x\"], y=fig1buy[\"y\"], mode='markers', marker=dict(color='green', symbol='triangle-up', size=8), name='BUY'))\n",
    "    fig1.add_trace(go.Scatter(x=fig1sell[\"x\"], y=fig1sell[\"y\"], mode='markers', marker=dict(color='red', symbol='triangle-down', size=8), name='SELL'))\n",
    "\n",
    "    # fig1_json = pio.to_json(fig1, validate=False)\n",
    "    # fig2_json = pio.to_json(fig2, validate=False)\n",
    "    \n",
    "    return fig1, fig2\n",
    "\n",
    "def plot_live_results(df, daily, tradewise, graph):\n",
    "\n",
    "    daily.drop('Close',axis=1,inplace=True)\n",
    "    daily['Close'] = df.Close.to_numpy()\n",
    "    fig1buy = pd.DataFrame()\n",
    "    fig1sell = pd.DataFrame()\n",
    "    \n",
    "    for _, row in daily.iterrows():\n",
    "        if row['signals'] > 0:\n",
    "            new_row = pd.DataFrame({\"x\": [row['datetime']], \"y\": [row['Close']], \"type\": [\"buy\"]})\n",
    "            print(\"rowclose\",row['Close'])\n",
    "            fig1buy = pd.concat([fig1buy, new_row], ignore_index=True)\n",
    "            print(f\"appending {_} to buy\")\n",
    "        elif row['signals'] < 0:\n",
    "            new_row = pd.DataFrame({\"x\": [row['datetime']], \"y\": [row['Close']], \"type\": [\"sell\"]})\n",
    "            fig1sell = pd.concat([fig1sell, new_row], ignore_index=True)\n",
    "            print(f\"appending {_} to sell\")\n",
    "\n",
    "    #  'g^', markersize=10\n",
    "    #  'rv', markersize=10\n",
    "    \n",
    "    \n",
    "    df1 = pd.DataFrame({\"x\": df.index, \"y\":df.Close, \"type\":\"line\"})\n",
    "    \n",
    "    df2 = pd.DataFrame({\"x\": df.index, \"y\":daily['portfolio value']})\n",
    "    \n",
    "    fig1 = go.Figure()\n",
    "    fig2=go.Figure()\n",
    "\n",
    "    fig1.add_trace(go.Scatter(x=df1[\"x\"], y=df1[\"y\"], mode='lines', name='ClosePrice'))\n",
    "    fig2.add_trace(go.Scatter(x=df2[\"x\"], y=df2[\"y\"], mode='lines', name='Portfolio'))\n",
    "\n",
    "    try:\n",
    "        fig1.add_trace(go.Scatter(x=fig1buy[\"x\"], y=fig1buy[\"y\"], mode='markers', marker=dict(color='green', symbol='triangle-up', size=8), name='BUY'))\n",
    "    except Exception as e:\n",
    "        print(e, end=\"\")\n",
    "        print(\"in buy\")\n",
    "    try:\n",
    "        fig1.add_trace(go.Scatter(x=fig1sell[\"x\"], y=fig1sell[\"y\"], mode='markers', marker=dict(color='red', symbol='triangle-down', size=8), name='SELL'))\n",
    "    except Exception as e:\n",
    "        print(e, end=\"\")\n",
    "        print(\"in sell\")\n",
    "    \n",
    "    print(fig1buy)\n",
    "    print(fig1sell)\n",
    "\n",
    "    \n",
    "    # fig1.add_trace(go.Scatter(x=fig1buy[\"x\"], y=fig1buy[\"y\"], mode='markers', marker=dict(color='green', symbol='triangle-up', size=8), name='BUY'))\n",
    "    # fig1.add_trace(go.Scatter(x=fig1sell[\"x\"], y=fig1sell[\"y\"], mode='markers', marker=dict(color='red', symbol='triangle-down', size=8), name='SELL'))\n",
    "    \n",
    "    # fig1_json = pio.to_json(fig1, validate=False)\n",
    "    # fig2_json = pio.to_json(fig2, validate=False)\n",
    "    \n",
    "    return fig1, fig2\n",
    "    \n",
    "\n",
    "def historical_trading(ticker, start_date, end_date):\n",
    "    # (Keep the existing implementation)\n",
    "    df, daily, tradewise, graph, metricstr = backtest_strategy(ticker, start_date, end_date)\n",
    "    try:\n",
    "        if (df)==None:\n",
    "            return daily, tradewise, metricstr, None, None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    daily['Close'] = df['close']\n",
    "    fig1, fig2 = plot_historical_results(df, daily, tradewise, graph)\n",
    "    return daily, tradewise, metricstr, fig1, fig2\n",
    "\n",
    "def live_trading(ticker, intv):\n",
    "    global should_stop\n",
    "    should_stop = False  # Reset the stop flag\n",
    "    datatrain = yf.download(ticker, \"2022-01-01\", \"2023-01-01\")\n",
    "    vix_symbol = \"^VIX\"\n",
    "    datatrain.columns = datatrain.columns.str.capitalize()\n",
    "    #data.columns = data.columns.str.capitalize()\n",
    "    #vix_data_t = yf.download(vix_symbol, import_date, sdate)\n",
    "    vix_data = yf.download(vix_symbol, \"2022-01-01\", \"2023-01-01\")\n",
    "    #data_train['VIX']=vix_data['Close']\n",
    "    datatrain['VIX']=vix_data['Close']\n",
    "    datatrain=gen_newdata(datatrain) # calculate the ichimoku metrics similar to historical for finding clustering params\n",
    "    datatrain = datatrain.dropna()\n",
    "    # return data_train, data\n",
    "    window=7\n",
    "    datatrain['rolling_min'] = datatrain['Low'].rolling(window=window).min()\n",
    "    datatrain['rolling_max'] = datatrain['High'].rolling(window=window).max()\n",
    "    datatrain['support'] = datatrain['rolling_min']\n",
    "    datatrain['resistance'] = datatrain['rolling_max']\n",
    "    datatrain['High_s']=datatrain['Close'].rolling(window=15).max()\n",
    "    datatrain['Low_s']=datatrain['Close'].rolling(window=15).min()\n",
    "    \n",
    "    \n",
    "    datatrain, center, scaler = trendpart(datatrain,\"2022-01-01\",\"2023-01-01\")# data_train now has another colmn for category\n",
    "    window_len = calclen(datatrain)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(1==1):\n",
    "    # try:\n",
    "        tmp= 0\n",
    "        while not should_stop:\n",
    "            tmp+=1\n",
    "            print(\"in while loop\", tmp)\n",
    "            data = yf.download(ticker, str(datetime.datetime.today()).split()[0], str(datetime.datetime.today()+100*datetime.timedelta(days=1)).split()[0], interval=intv)\n",
    "            vix_data = yf.download(vix_symbol, str(datetime.datetime.today()).split()[0], str(datetime.datetime.today()+100*datetime.timedelta(days=1)).split()[0], interval=intv)\n",
    "            data['VIX']=vix_data['Close']\n",
    "            data=gen_newdata(data)\n",
    "            # data.columns = data.columns.str.lower()\n",
    "            data['rolling_min'] = data['Low'].rolling(window=window).min()\n",
    "            data['rolling_max'] = data['High'].rolling(window=window).max()\n",
    "            data['support'] = data['rolling_min']\n",
    "            data['resistance'] = data['rolling_max']\n",
    "            data['High_s']=data['Close'].rolling(window=15).max()\n",
    "            data['Low_s']=data['Close'].rolling(window=15).min()\n",
    "            if(len(data)<10):\n",
    "                print('Looping As data less than 10', data)\n",
    "                continue          \n",
    "            pred_arr = []\n",
    "            for i in range(len(data)):\n",
    "                pred_arr.append(find_category(data.iloc[i],center,scaler))\n",
    "        \n",
    "            data['category'] = 0\n",
    "            data['category']=pred_arr\n",
    "            #max pooling\n",
    "            data['category_pool']=max_pooling(data['category'],pool_size=20)\n",
    "        \n",
    "            # shift category down by window_len to not use future value\n",
    "            data['category_pool']=data['category_pool'].shift(window_len)\n",
    "            window=7\n",
    "            data['rolling_min'] = data['Low'].rolling(window=window).min()\n",
    "            data['rolling_max'] = data['High'].rolling(window=window).max()\n",
    "            data['support'] = data['rolling_min']\n",
    "            data['resistance'] = data['rolling_max']\n",
    "            \n",
    "            # now every category corresponds to correct close price\n",
    "            total_signals = []\n",
    "            current_win_sig = []\n",
    "            num_segments = len(data) // window_len\n",
    "            for seg_no in range(num_segments):\n",
    "                segment = data.iloc[seg_no * window_len: min(len(data),(seg_no + 1) * window_len)]\n",
    "                category = segment['category_pool'].iloc[0]  # Get the category of the current segment\n",
    "                if category == 0:\n",
    "                    segment = strat1(segment)\n",
    "                    segment=clean_signals(segment)\n",
    "                    segment=ATR_SL(segment,segment,segment['signals'],1)\n",
    "                    current_win_sig=segment['signals']\n",
    "                    \n",
    "                elif category == 1:\n",
    "                    segment = strat2(segment)\n",
    "                    segment=clean_signals(segment)\n",
    "                    segment=ATR_SL(segment,segment,segment['signals'],2)\n",
    "                    current_win_sig=segment['signals']\n",
    "                elif category == 2:\n",
    "                    segment = strat3(segment)\n",
    "                    segment=clean_signals(segment)\n",
    "                    segment=ATR_SL(segment,segment,segment['signals'],3)\n",
    "                    current_win_sig=segment['signals']\n",
    "                elif category == 3:\n",
    "                    segment = strat4(segment)\n",
    "                    segment=clean_signals(segment)\n",
    "                    segment=ATR_SL(segment,segment,segment['signals'],4)\n",
    "                    current_win_sig=segment['signals']\n",
    "        \n",
    "                # Ensure the signals are clean (preprocess within the strategy function or here)\n",
    "                total_signals.extend(current_win_sig)\n",
    "        \n",
    "            # make length of toal_sigmals and data equal by appending 0s in total_signlas\n",
    "            if len(total_signals) < len(data):\n",
    "                total_signals.extend([0] * (len(data) - len(total_signals)))\n",
    "    \n",
    "            data[\"signals\"] = total_signals\n",
    "    \n",
    "    \n",
    "            data['low']=data['Low']\n",
    "            data['high']=data['High']\n",
    "            data['close']=data['Close']\n",
    "            data['open']=data['Open']\n",
    "            data['volume']=data['Volume']\n",
    "            data['datetime'] = data.index\n",
    "            \n",
    "            Testing_signals = TradingStrategy_Compounding(data)\n",
    "            to_submit_comp, tradewise, daily, graph, metricstr = Testing_signals.compounding()\n",
    "        \n",
    "            \n",
    "            # returnables = backtest(data, 1, 1, data[\"FinalSignals\"])  # Adjust the parameters as necessary\n",
    "        \n",
    "            #return data, daily, tradewise, graph, metricstr\n",
    "    \n",
    "            #df_live, daily, tradewise, graph, metricstr = forwardtest_strategy(data)\n",
    "            fig1, fig2 = plot_live_results(data, daily, tradewise, graph)\n",
    "    \n",
    "            yield fig1, tradewise, metricstr, fig2\n",
    "            \n",
    "            time.sleep(3) # refresh rate\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(f\"An error occurred: {e}\")\n",
    "    #     print(data)\n",
    "    # finally:\n",
    "    #     print(\"in the finally block\")\n",
    "    #     pass\n",
    "    #     # yield None, None, f\"Trading stopped. Final metrics:\", None\n",
    "\n",
    "def stop_trading():\n",
    "    global should_stop\n",
    "    should_stop = True\n",
    "    print(\"Trading stop signal sent.\")\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Trading Bot Interface\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Historical Trading\"):\n",
    "            with gr.Row():\n",
    "                ticker_hist = gr.Textbox(label=\"Enter Ticker Symbol\")\n",
    "                start_date = gr.Textbox(label=\"Start Date (YYYY-MM-DD)\")\n",
    "                end_date = gr.Textbox(label=\"End Date (YYYY-MM-DD)\")\n",
    "            submit_hist = gr.Button(\"Run Historical Trading\")\n",
    "            \n",
    "            daily = gr.Dataframe(label=\"Daily Data\")\n",
    "            tradewise = gr.Dataframe(label=\"Trade-wise Data\")\n",
    "            metricstr = gr.Textbox(label=\"Metrics\")\n",
    "# PLOT1 ______________________\n",
    "            plot1 = gr.Plot()\n",
    "# PLOT2________________________\n",
    "            plot2 = gr.Plot()\n",
    "\n",
    "        with gr.TabItem(\"Live Trading\"):\n",
    "            with gr.Row():\n",
    "                ticker_live = gr.Textbox(label=\"Enter Ticker Symbol\", scale=3)\n",
    "                options = ['1m', '2m', '5m', '15m', '30m', '60m', '90m', '1h', '1d']\n",
    "                intv = gr.Dropdown(choices=options, label=\"Select Time Interval\", value=options[0], scale=1)\n",
    "                \n",
    "            with gr.Row():\n",
    "                live_submit = gr.Button(\"Start Live Trading\")\n",
    "                stop_button = gr.Button(\"Stop Trading\")\n",
    "            live_plot_close = gr.Plot(label=\"Live Trading Plot\")\n",
    "            live_tradewise = gr.Dataframe(label=\"Trade-wise Data\")\n",
    "            portfolio_plot = gr.Plot(label=\"Portfolio\")\n",
    "\n",
    "\n",
    "            live_metrics = gr.Textbox(label=\"Final Metrics\")\n",
    "\n",
    "    \n",
    "    # Link the buttons to functions\n",
    "    submit_hist.click(\n",
    "        historical_trading,\n",
    "        inputs=[ticker_hist, start_date, end_date], \n",
    "        outputs=[daily, tradewise, metricstr, plot1, plot2]\n",
    "    )\n",
    "    live_submit.click(\n",
    "        live_trading, \n",
    "        inputs=[ticker_live, intv], \n",
    "        outputs=[live_plot_close, live_tradewise, live_metrics, portfolio_plot]\n",
    "    )\n",
    "    stop_button.click(stop_trading)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b750c3a0-1ac0-4be3-9e43-bee715e7ff9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707f8a0-9da9-4ea0-9393-d7d0181c086e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d250a-c425-431f-ac4a-ea31dc7a4109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa43e4-ffb3-40ad-a59c-1662ef577213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667984c-3cf3-42cb-941a-c6ec1f11df45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f4694-d699-4f03-8bc6-c8a1824453a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2fb84-7eda-4747-8109-0a50d90e80c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5195a92-4442-4608-b078-b1dc24399ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00ae21-5921-4180-b1c6-9b785e14263d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fe1d8-4ff4-4f8c-83fe-6fb06927e2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb573f6f-3ed3-4dab-91be-9e88a6ad1b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937acfc9-3a19-4cf6-8083-4585adf067dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e52fda-71dd-40a2-8a10-8a156e87c5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1679a-29a3-41a3-8719-65a784a5a6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd88c39-9f30-48d4-a114-5d123ce027e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabd4d9-774a-4e35-b8d6-465480d81ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea510f1-dc36-4811-9a1a-a267a8143181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04896ec-c5c8-45a2-9939-be439a8b55a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3d056-9988-4eb1-9cf6-c996d28519b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2576777-581b-4bf4-9f08-07595c52cd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526a242-f914-4972-9159-744cd167977e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db0df6-48a9-464f-8a29-e53adacd097e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63ff43-6c80-43f6-be40-0b7e1463ea69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be23239-5fa6-4dc8-a987-e0867b969e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3c225-f695-4c5a-b786-a83555c355b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125d921-9693-4e05-9c17-2424311b4e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f7c63-a77c-4634-b05c-837d80206b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6e81c-3ebd-4239-a570-133176aab7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34418483-d31e-4d3b-8ab0-07725329ab27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbb208-061a-40a1-a8f4-caa54b40c06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d0824-9688-46d6-8827-184132bf2c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5b337d-35ce-444c-93ff-eba385572987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854ce0d-d2eb-441f-a0b9-2ddadda45e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9df2f-9602-4248-8c46-b043e3fe504e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e2da0-b748-4105-b65f-432319e84ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d89ece4-4c6c-4fd4-adb3-aa3dc1e57e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d79f5-3ed6-49cf-8b1e-674c2252fb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6058dc-7cdd-49a2-a653-7133fd2faa63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5522d-5f5b-4c23-bc62-c2c28579bbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bbbfd-9fb9-4986-a3c3-ee5536e181ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbd465-09de-4fcc-9623-ddbb8cade6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdeb6b-5f3d-4e42-a703-be09e229d0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
